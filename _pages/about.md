---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


I am a second-year Ph.D. student in Machine Learning Department, School of Computer Science, Carnegie Mellon University, advised by [Prof. Yiming Yang](https://www.cs.cmu.edu/~./yiming/). I received my Bachelor's degree in computer science, with a minor in mathematics, from Peking university, where I was advised by [Prof. Liwei Wang](http://www.liweiwang-pku.com/) and [Prof. Di He](https://dihe-pku.github.io/). I was a student researcher at Google Research in 2023, where I enjoyed working with [Dr. Srinadh Bhojanapalli](https://bsrinadh.github.io/).

My research goal is to develop machine intelligence methods that better _augment_ human intelligence. Towards this goal, I study the behavior and limitations of existing machine learning methods through both theoretical and empirical lens, guiding the development of new methods and principled model scaling. On the application side, I work on deep learning methods for mathematical reasoning, code generation, and partial differential equation solving.

My detailed CV can be found [here](https://lithiumda.github.io/files/CV.pdf).

Selected Publications (one per year)
=====
**2024:** **An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models** (in submission) [[PDF](https://arxiv.org/abs/2408.00724v1)]  
  Yangzhen Wu, Zhiqing Sun, **Shanda Li**, Sean Welleck, Yiming Yang

**2023:** **Functional Interpolation for Relative Positions Improves Long Context Transformers** (ICLR 2024) [[PDF](https://arxiv.org/abs/2310.04418)]  
  **Shanda Li**, Chong You, Guru Guruganesh, Joshua Ainslie, Santiago Ontanon, Manzil Zaheer, Sumit Sanghai, Yiming Yang, Sanjiv Kumar, Srinadh Bhojanapalli

**2022:**  **Is $L^2$ Physics-Informed Loss Always Suitable for Training Physics-Informed Neural Network?** (NeurIPS 2022) [[PDF](https://arxiv.org/abs/2206.02016)]  
  Chuwei Wang\*, **Shanda Li**\*, Di He, Liwei Wang  

**2021:** **Stable, Fast and Accurate: Kernelized Attention with Relative Positional Encoding** (NeurIPS 2021) [[PDF](https://arxiv.org/abs/2106.12566)]  
  Shengjie Luo\*, **Shanda Li**\*, Tianle Cai, Di He, Dinglan Peng, Shuxin Zheng, Guolin Ke, Liwei Wang, Tie-Yan Liu  

<!-- [3] **Your Transformer May Not be as Powerful as You Expect** (NeurIPS 2022) [[PDF](https://arxiv.org/abs/2205.13401)]  
  Shengjie Luo\*, **Shanda Li**\*, Shuxin Zheng, Tie-Yan Liu, Liwei Wang, Di He

[5] **Learning Physics-Informed Neural Networks without Stacked Back-propagation** (AISTATS 2023)  [[PDF](https://arxiv.org/abs/2202.09340)]  
  Di He, **Shanda Li**, Wenlei Shi, Xiaotian Gao, Jia Zhang, Jiang Bian, Liwei Wang, Tie-Yan Liu -->

<!-- [6] **Can Vision Transformers Perform Convolution?** (Preprint) [[PDF](https://arxiv.org/abs/2111.01353)]  
  **Shanda Li**, Xiangning Chen, Di He, Cho-Jui Hsieh   -->

Blogs
====
**July 29, 2024** [CMU-MATH Teamâ€™s Innovative Approach Secures 2nd Place at the AIMO Prize](https://blog.ml.cmu.edu/2024/07/29/cmu-math-teams-innovative-approach-secures-2nd-place-at-the-aimo-prize/) (Published on [CMU ML Blog](https://blog.ml.cmu.edu/))